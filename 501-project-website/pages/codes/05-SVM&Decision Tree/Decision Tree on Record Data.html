<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>decision-tree-on-record-data</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="Decision Tree on Record Data_files/libs/clipboard/clipboard.min.js"></script>
<script src="Decision Tree on Record Data_files/libs/quarto-html/quarto.js"></script>
<script src="Decision Tree on Record Data_files/libs/quarto-html/popper.min.js"></script>
<script src="Decision Tree on Record Data_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Decision Tree on Record Data_files/libs/quarto-html/anchor.min.js"></script>
<link href="Decision Tree on Record Data_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Decision Tree on Record Data_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Decision Tree on Record Data_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Decision Tree on Record Data_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Decision Tree on Record Data_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<section id="classify-record-data-by-decision-tree" class="level1">
<h1>Classify record data by Decision Tree</h1>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>A decision tree is a decision support tool that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.</p>
<p>In this document, I use the decision tree classification algorithm in scikit-learn to classify my cleaned record data. To improve the accuracy of the classifier, I also perform parameter selection to improve the performance of the model by reducing the number of parameters and eliminating some parameters that are not highly relevant. Next, I debug the parameters of the model through a series of methods to find the most suitable hyperparameters for the model, and train the optimal model to arrive at the final classifier.</p>
<p>The dataset used is a cleaned credit score dataset. The reason for using decision trees for this dataset is that I tried this dataset with two methods (decision trees and SVM) before formally completing this document, and the classification results of SVM were very poor and unsatisfactory, so I decided to use decision tree classification for this dataset.</p>
</section>
<section id="theory" class="level2">
<h2 class="anchored" data-anchor-id="theory">Theory</h2>
<p>A decision tree is a flowchart-like tree structure where an internal node represents feature(or attribute), the branch represents a decision rule, and each leaf node represents the outcome. The topmost node in a decision tree is known as the root node. It learns to partition on the basis of the attribute value. It partitions the tree in recursively manner call recursive partitioning. This flowchart-like structure helps you in decision making. It’s visualization like a flowchart diagram which easily mimics the human level thinking. That is why decision trees are easy to understand and interpret.</p>
<p><img src="dt.png" class="img-fluid"></p>
<p>Decision Tree is a white box type of ML algorithm. It shares internal decision-making logic, which is not available in the black box type of algorithms such as Neural Network. Its training time is faster compared to the neural network algorithm. The time complexity of decision trees is a function of the number of records and number of attributes in the given data. The decision tree is a distribution-free or non-parametric method, which does not depend upon probability distribution assumptions. Decision trees can handle high dimensional data with good accuracy.</p>
<p>The basic idea behind any decision tree algorithm is as follows:</p>
<ul>
<li>Select the best attribute using Attribute Selection Measures(ASM) to split the records.</li>
<li>Make that attribute a decision node and breaks the dataset into smaller subsets.</li>
<li>Starts tree building by repeating this process recursively for each child until one of the condition will match:
<ul>
<li>All the tuples belong to the same attribute value.</li>
<li>here are no more remaining attributes.</li>
<li>There are no more instances.</li>
</ul></li>
</ul>
</section>
<section id="methods" class="level2">
<h2 class="anchored" data-anchor-id="methods">Methods</h2>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>record <span class="op">=</span> pd.read_csv(<span class="st">"clean_record_data.csv"</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>record.head()</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>record <span class="op">=</span> record.drop(columns<span class="op">=</span>[<span class="st">'Unnamed: 0'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Normalize the data and divide it into a training set and a test set</strong></p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> record.drop(columns<span class="op">=</span>[<span class="st">'Credit_Score'</span>])</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> record[<span class="st">'Credit_Score'</span>]</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>scalar <span class="op">=</span> StandardScaler()</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>scalar.fit(X)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> scalar.transform(X)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size <span class="op">=</span> <span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>See the shape of data and Count the distribution of the labels</strong></p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the shape of the train and test sets, and levels of the depencent variable (Y) </span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_train.shape)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_test.shape)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_train.shape)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_test.shape)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(record[<span class="st">'Credit_Score'</span>].value_counts())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(78239, 39)
(19560, 39)
(78239,)
(19560,)
1    52020
0    28328
2    17451
Name: Credit_Score, dtype: int64</code></pre>
</div>
</div>
<section id="baseline-model" class="level3">
<h3 class="anchored" data-anchor-id="baseline-model">Baseline Model</h3>
<p><strong>Decision Tree Model on Recorded Data</strong></p>
<p>Use DecisionTreeClassifier() function to build the model and fit data. Here I set the initial parameter max_depth=6. Then make predictions on both training set and test set.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> tree</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> tree.DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">6</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.fit(X_train, y_train)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>yp_train <span class="op">=</span> model.predict(X_train)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>yp_test <span class="op">=</span> model.predict(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Confusion matrix of training set.</strong></p>
<p>In the confusion matrix, we can visualize how well the model is classified, how much data is correctly classified and how much data is incorrectly classified. For a multi-category problem, for example, this dataset has three categories of labels, so the size of the confusion matrix is <span class="math inline">\(3\times 3\)</span>. Also compute the accuracy, precision and recall for the resutls.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>cm1 <span class="op">=</span> confusion_matrix(y_train, yp_train, labels<span class="op">=</span>model.classes_)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>disp1 <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm1, display_labels<span class="op">=</span>model.classes_)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>disp1.plot()</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Confusion Matrix on Train set"</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>cm2 <span class="op">=</span> confusion_matrix(y_test, yp_test, labels<span class="op">=</span>model.classes_)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>disp2 <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm2, display_labels<span class="op">=</span>model.classes_)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>disp2.plot()</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Confusion Matrix on Test set"</span>)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Decision%20Tree%20on%20Record%20Data_files/figure-html/cell-6-output-1.png" width="521" height="449"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Decision%20Tree%20on%20Record%20Data_files/figure-html/cell-6-output-2.png" width="513" height="449"></p>
</div>
</div>
<p><strong>Visualize the tree.</strong></p>
<p>First we visualilze the tree in a text version. This is due to the fact that the amount of data is relatively large and drawing the graph takes a long time, while the text version allows us to see the results more quickly.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>text_representation <span class="op">=</span> tree.export_text(model)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(text_representation)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>|--- feature_1 &lt;= -0.30
|   |--- feature_0 &lt;= 0.32
|   |   |--- feature_38 &lt;= 0.56
|   |   |   |--- feature_4 &lt;= -1.55
|   |   |   |   |--- class: 2
|   |   |   |--- feature_4 &gt;  -1.55
|   |   |   |   |--- feature_15 &lt;= 11.33
|   |   |   |   |   |--- feature_3 &lt;= -1.16
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |   |--- feature_3 &gt;  -1.16
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |--- feature_15 &gt;  11.33
|   |   |   |   |   |--- feature_15 &lt;= 14.32
|   |   |   |   |   |   |--- class: 2
|   |   |   |   |   |--- feature_15 &gt;  14.32
|   |   |   |   |   |   |--- class: 1
|   |   |--- feature_38 &gt;  0.56
|   |   |   |--- feature_3 &lt;= -1.34
|   |   |   |   |--- class: 0
|   |   |   |--- feature_3 &gt;  -1.34
|   |   |   |   |--- feature_9 &lt;= -1.23
|   |   |   |   |   |--- feature_2 &lt;= -0.79
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |   |--- feature_2 &gt;  -0.79
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |--- feature_9 &gt;  -1.23
|   |   |   |   |   |--- feature_4 &lt;= -1.20
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |   |--- feature_4 &gt;  -1.20
|   |   |   |   |   |   |--- class: 1
|   |--- feature_0 &gt;  0.32
|   |   |--- feature_13 &lt;= -0.47
|   |   |   |--- feature_13 &lt;= -0.60
|   |   |   |   |--- feature_5 &lt;= 1.18
|   |   |   |   |   |--- feature_3 &lt;= -1.19
|   |   |   |   |   |   |--- class: 2
|   |   |   |   |   |--- feature_3 &gt;  -1.19
|   |   |   |   |   |   |--- class: 2
|   |   |   |   |--- feature_5 &gt;  1.18
|   |   |   |   |   |--- feature_13 &lt;= -0.92
|   |   |   |   |   |   |--- class: 2
|   |   |   |   |   |--- feature_13 &gt;  -0.92
|   |   |   |   |   |   |--- class: 1
|   |   |   |--- feature_13 &gt;  -0.60
|   |   |   |   |--- feature_7 &lt;= 0.13
|   |   |   |   |   |--- feature_15 &lt;= -0.38
|   |   |   |   |   |   |--- class: 2
|   |   |   |   |   |--- feature_15 &gt;  -0.38
|   |   |   |   |   |   |--- class: 2
|   |   |   |   |--- feature_7 &gt;  0.13
|   |   |   |   |   |--- feature_10 &lt;= 0.92
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |   |--- feature_10 &gt;  0.92
|   |   |   |   |   |   |--- class: 2
|   |   |--- feature_13 &gt;  -0.47
|   |   |   |--- feature_13 &lt;= -0.47
|   |   |   |   |--- feature_9 &lt;= -1.27
|   |   |   |   |   |--- feature_17 &lt;= 3.19
|   |   |   |   |   |   |--- class: 0
|   |   |   |   |   |--- feature_17 &gt;  3.19
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |--- feature_9 &gt;  -1.27
|   |   |   |   |   |--- feature_13 &lt;= -0.47
|   |   |   |   |   |   |--- class: 0
|   |   |   |   |   |--- feature_13 &gt;  -0.47
|   |   |   |   |   |   |--- class: 1
|   |   |   |--- feature_13 &gt;  -0.47
|   |   |   |   |--- feature_3 &lt;= -0.85
|   |   |   |   |   |--- feature_10 &lt;= -1.22
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |   |--- feature_10 &gt;  -1.22
|   |   |   |   |   |   |--- class: 2
|   |   |   |   |--- feature_3 &gt;  -0.85
|   |   |   |   |   |--- feature_32 &lt;= 1.10
|   |   |   |   |   |   |--- class: 2
|   |   |   |   |   |--- feature_32 &gt;  1.10
|   |   |   |   |   |   |--- class: 1
|--- feature_1 &gt;  -0.30
|   |--- feature_0 &lt;= -1.00
|   |   |--- feature_13 &lt;= 3.48
|   |   |   |--- feature_7 &lt;= 2.61
|   |   |   |   |--- feature_38 &lt;= 0.56
|   |   |   |   |   |--- feature_28 &lt;= 1.81
|   |   |   |   |   |   |--- class: 0
|   |   |   |   |   |--- feature_28 &gt;  1.81
|   |   |   |   |   |   |--- class: 0
|   |   |   |   |--- feature_38 &gt;  0.56
|   |   |   |   |   |--- feature_5 &lt;= 2.17
|   |   |   |   |   |   |--- class: 0
|   |   |   |   |   |--- feature_5 &gt;  2.17
|   |   |   |   |   |   |--- class: 0
|   |   |   |--- feature_7 &gt;  2.61
|   |   |   |   |--- feature_2 &lt;= 1.39
|   |   |   |   |   |--- feature_11 &lt;= 1.11
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |   |--- feature_11 &gt;  1.11
|   |   |   |   |   |   |--- class: 0
|   |   |   |   |--- feature_2 &gt;  1.39
|   |   |   |   |   |--- feature_5 &lt;= 0.68
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |   |--- feature_5 &gt;  0.68
|   |   |   |   |   |   |--- class: 0
|   |   |--- feature_13 &gt;  3.48
|   |   |   |--- feature_7 &lt;= 0.69
|   |   |   |   |--- feature_38 &lt;= 0.56
|   |   |   |   |   |--- class: 0
|   |   |   |   |--- feature_38 &gt;  0.56
|   |   |   |   |   |--- class: 1
|   |   |   |--- feature_7 &gt;  0.69
|   |   |   |   |--- feature_2 &lt;= 1.62
|   |   |   |   |   |--- feature_11 &lt;= -0.38
|   |   |   |   |   |   |--- class: 0
|   |   |   |   |   |--- feature_11 &gt;  -0.38
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |--- feature_2 &gt;  1.62
|   |   |   |   |   |--- class: 0
|   |--- feature_0 &gt;  -1.00
|   |   |--- feature_0 &lt;= 0.32
|   |   |   |--- feature_38 &lt;= 0.56
|   |   |   |   |--- feature_33 &lt;= 1.05
|   |   |   |   |   |--- feature_37 &lt;= 1.05
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |   |--- feature_37 &gt;  1.05
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |--- feature_33 &gt;  1.05
|   |   |   |   |   |--- feature_12 &lt;= -1.07
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |   |--- feature_12 &gt;  -1.07
|   |   |   |   |   |   |--- class: 1
|   |   |   |--- feature_38 &gt;  0.56
|   |   |   |   |--- feature_7 &lt;= 0.75
|   |   |   |   |   |--- feature_9 &lt;= 2.93
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |   |--- feature_9 &gt;  2.93
|   |   |   |   |   |   |--- class: 0
|   |   |   |   |--- feature_7 &gt;  0.75
|   |   |   |   |   |--- feature_2 &lt;= -0.91
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |   |--- feature_2 &gt;  -0.91
|   |   |   |   |   |   |--- class: 1
|   |   |--- feature_0 &gt;  0.32
|   |   |   |--- feature_38 &lt;= 0.56
|   |   |   |   |--- feature_33 &lt;= 1.05
|   |   |   |   |   |--- feature_30 &lt;= 1.80
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |   |--- feature_30 &gt;  1.80
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |--- feature_33 &gt;  1.05
|   |   |   |   |   |--- feature_3 &lt;= 0.99
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |   |--- feature_3 &gt;  0.99
|   |   |   |   |   |   |--- class: 1
|   |   |   |--- feature_38 &gt;  0.56
|   |   |   |   |--- feature_15 &lt;= 0.69
|   |   |   |   |   |--- feature_3 &lt;= 1.33
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |   |--- feature_3 &gt;  1.33
|   |   |   |   |   |   |--- class: 0
|   |   |   |   |--- feature_15 &gt;  0.69
|   |   |   |   |   |--- feature_13 &lt;= 3.39
|   |   |   |   |   |   |--- class: 1
|   |   |   |   |   |--- feature_13 &gt;  3.39
|   |   |   |   |   |   |--- class: 0
</code></pre>
</div>
</div>
<p>Then use graphviz package to visualize the tree. In the graph we can see the tree is pretty wide.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> graphviz</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_tree(model,X,Y):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    dot_data <span class="op">=</span> tree.export_graphviz(model, out_file<span class="op">=</span><span class="va">None</span>, </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>                                feature_names<span class="op">=</span>X,  </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>                                class_names<span class="op">=</span>Y)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    graph <span class="op">=</span> graphviz.Source(dot_data, <span class="bu">format</span><span class="op">=</span><span class="st">"png"</span>) </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> graph</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> record.columns.delete(<span class="dv">2</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> [<span class="st">"0"</span>,<span class="st">"1"</span>,<span class="st">"2"</span>]</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>plot_tree(model,feature_names,class_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>ExecutableNotFound: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>&lt;graphviz.sources.Source at 0x7fb0f0ad69d0&gt;</code></pre>
</div>
</div>
<p><strong>Accuracy, precision and recall</strong></p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score,confusion_matrix</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy(train) of model is </span><span class="sc">{}</span><span class="st">%"</span>.<span class="bu">format</span>(accuracy_score(y_test,yp_test) <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy(test) of model is </span><span class="sc">{}</span><span class="st">%"</span>.<span class="bu">format</span>(accuracy_score(y_train,yp_train) <span class="op">*</span> <span class="dv">100</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy(train) of model is 59.48875255623722%
Accuracy(test) of model is 59.80904663914416%</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># train</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"------TRAIN------"</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_train,yp_train))</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># test</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"------TEST------"</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test,yp_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>------TRAIN------
              precision    recall  f1-score   support

           0       0.60      0.40      0.48     22737
           1       0.66      0.67      0.66     41602
           2       0.47      0.71      0.57     13900

    accuracy                           0.60     78239
   macro avg       0.58      0.59      0.57     78239
weighted avg       0.61      0.60      0.59     78239

------TEST------
              precision    recall  f1-score   support

           0       0.60      0.39      0.48      5591
           1       0.66      0.66      0.66     10418
           2       0.46      0.71      0.56      3551

    accuracy                           0.59     19560
   macro avg       0.58      0.59      0.57     19560
weighted avg       0.61      0.59      0.59     19560
</code></pre>
</div>
</div>
</section>
<section id="feature-selection" class="level3">
<h3 class="anchored" data-anchor-id="feature-selection">Feature Selection</h3>
<p>In this part, I used SelctFromModel() function to complete feature selection. Linear models penalized with the L1 norm have sparse solutions: many of their estimated coefficients are zero. When the goal is to reduce the dimensionality of the data to use with another classifier, they can be used along with SelectFromModel to select the non-zero coefficients. In particular, sparse estimators useful for this purpose are the Lasso for regression, and of LogisticRegression and LinearSVC for classification:</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>X.shape</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_selection <span class="im">import</span> SelectFromModel</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> LinearSVC</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co">#lsvc = LinearSVC(C=0.01, penalty="l1", dual=False).fit(X, y)</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>selectmodel <span class="op">=</span> SelectFromModel(model, prefit<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>X_new <span class="op">=</span> selectmodel.transform(X)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>X_new.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>(97799, 2)</code></pre>
</div>
</div>
</section>
<section id="model-tuning" class="level3">
<h3 class="anchored" data-anchor-id="model-tuning">Model Tuning</h3>
<p><strong>Here I used GridSearchCV() function to complete model tuning</strong></p>
<p>The parameters to be tuned are max_depth, min_samples_leaf and criterion.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the parameter grid based on the results of random search </span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>],</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_leaf'</span>: [<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">50</span>, <span class="dv">100</span>],</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'criterion'</span>: [<span class="st">"gini"</span>, <span class="st">"entropy"</span>]</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>model, </span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>                           param_grid<span class="op">=</span>params, </span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>                           cv<span class="op">=</span><span class="dv">4</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, verbose<span class="op">=</span><span class="dv">1</span>, scoring <span class="op">=</span> <span class="st">"accuracy"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 4 folds for each of 50 candidates, totalling 200 fits</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>GridSearchCV(cv=4, estimator=DecisionTreeClassifier(max_depth=6), n_jobs=-1,
             param_grid={'criterion': ['gini', 'entropy'],
                         'max_depth': [2, 3, 5, 10, 20],
                         'min_samples_leaf': [5, 10, 20, 50, 100]},
             scoring='accuracy', verbose=1)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>grid_search.best_estimator_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>DecisionTreeClassifier(max_depth=3, min_samples_leaf=10)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_model(dt_classifier):</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Train Accuracy :"</span>, accuracy_score(y_train, dt_classifier.predict(X_train)))</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Train Confusion Matrix:"</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(confusion_matrix(y_train, dt_classifier.predict(X_train)))</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Test Accuracy :"</span>, accuracy_score(y_test, dt_classifier.predict(X_test)))</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Test Confusion Matrix:"</span>)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(confusion_matrix(y_test, dt_classifier.predict(X_test)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Fit the best model and evaluate the results.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>dt_best <span class="op">=</span> grid_search.best_estimator_</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>evaluate_model(dt_best)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Train Accuracy : 0.5945755952913508
Train Confusion Matrix:
[[ 8923 10467  3347]
 [ 5707 27327  8568]
 [  228  3403 10269]]
--------------------------------------------------
Test Accuracy : 0.5952965235173824
Test Confusion Matrix:
[[2204 2496  891]
 [1386 6812 2220]
 [  55  868 2628]]</code></pre>
</div>
</div>
<p>Plot the best tree.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>plot_tree(dt_best,feature_names,class_names)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>ExecutableNotFound: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>&lt;graphviz.sources.Source at 0x7fb0f0eeae50&gt;</code></pre>
</div>
</div>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>For data preprocessing, I standardized the data set. For the decision tree model, first I randomly chose the parameter <code>max_depth=6</code> and use all the other parameters as default. The result of the baseline model turns out that the performance is not good. The original accuracy score is only about 0.59 which means only 59% of the data were correctly classified. And we could see the tree plot that the original tree was very complex and there were many nodes. So I didn’t think it is a good model.</p>
<p>So in order to improve the model performance, I did feature selection and model tuning. In the final result, the best model was given through GridSearch function: <code>max_depth=2</code> and <code>min_samples_leaf=5</code>. Finally I plot the decision tree and it looked better. But the model accuracy has not changed a lot.</p>
</section>
<section id="conlusions" class="level2">
<h2 class="anchored" data-anchor-id="conlusions">Conlusions</h2>
<p>Here I summarized some pros and cons of the decision tree classifier.</p>
<ul>
<li>Pros
<ul>
<li>Decision trees are easy to interpret and visualize.</li>
<li>It can easily capture Non-linear patterns.</li>
<li>It requires fewer data preprocessing from the user, for example, there is no need to normalize columns.</li>
<li>It can be used for feature engineering such as predicting missing values, suitable for variable selection.</li>
<li>The decision tree has no assumptions about distribution because of the non-parametric nature of the algorithm. (Source)</li>
</ul></li>
<li>Cons
<ul>
<li>Sensitive to noisy data. It can overfit noisy data.</li>
<li>The small variation(or variance) in data can result in the different decision tree. This can be reduced by bagging and boosting algorithms.</li>
<li>Decision trees are biased with imbalance dataset, so it is recommended that balance out the dataset before creating the decision tree.</li>
</ul></li>
</ul>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<p>https://www.datacamp.com/tutorial/decision-tree-classification-python</p>
<p>https://why-change.com/2021/11/13/how-to-create-decision-trees-for-business-rules-analysis/</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>