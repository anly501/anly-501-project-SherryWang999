<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>clustering_quarto</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="Clustering_quarto_files/libs/clipboard/clipboard.min.js"></script>
<script src="Clustering_quarto_files/libs/quarto-html/quarto.js"></script>
<script src="Clustering_quarto_files/libs/quarto-html/popper.min.js"></script>
<script src="Clustering_quarto_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Clustering_quarto_files/libs/quarto-html/anchor.min.js"></script>
<link href="Clustering_quarto_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Clustering_quarto_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Clustering_quarto_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Clustering_quarto_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Clustering_quarto_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<section id="clustering-with-3-methods" class="level1">
<h1>Clustering with 3 methods</h1>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In this part, I will make clusterings on my record data and labeled data using 3 unsupervised clustering algorithms: K-Means, DBSCAN and hierarchical clustering. The purpose is that I want to have a look at whether these 3 methods could process my data and find natural clusters(groups) if they exist in the data.</p>
<p>For my data, I will divide a feature <code>X</code> without any label to satisfy the clustering algorithm. I want to use these three algorithms to cluster the data and try to see how the clustering without labels resembles the results of the labels that come with the original dataset.</p>
</section>
<section id="theory" class="level1">
<h1>Theory</h1>
<ol type="1">
<li><p>Kmeans clustering can be said to be the most common clustering algorithm, it is based on the division method clustering, the principle is to first initialize k cluster class centers, based on the calculation of the distance between the sample and the centroid to group the samples belonging to each cluster class, iteration to achieve the goal of the minimum distance between the sample and the center of the cluster class to which it belongs.</p>
<p>Besides launching a baseline model for kmeans using scikit-learn, I use a elbow method to make sure the optimal number of clusters. By drawing graphs and making some random try, I finally determine the optimal parameters.</p></li>
<li><p>The principle of DBSCAN is to identify points in “crowded” regions of the feature space where many data points are close together. These regions are called dense regions in the feature space. The idea behind DBSCAN is that clusters form dense regions of data separated by relatively empty regions.</p>
<p>DBSCAN is more complex than Kmeans, it can process non-linear data. In the implementation, I try to select the optimal <code>eps</code> and <code>min_samples</code> in the model and make a lot of try.</p></li>
<li><p>Hierarchical clustering is the hierarchical decomposition of a given set of data objects. According to the decomposition strategy used for hierarchical decomposition, hierarchical clustering can be further divided into cohesive (agglomerative, i.e., top-down) and divisive (i.e., bottom-up) hierarchical clustering.</p>
<p>The most notable feature of hierarchial clustering is that it uses dendrograms to visualize the clustering results and people can have different and multiple clustering results using only one simple dendrogram.</p></li>
</ol>
<p>Import packages</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.cluster.hierarchy <span class="im">import</span> dendrogram, linkage</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> AgglomerativeClustering</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Import data and make a quick view. In previous classification works, the data should contain labels, but here I will divide my feature X without labels. In my data set, the label column is <code>Credit_Score</code>.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"clean_record_data.csv"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop(columns<span class="op">=</span>[<span class="st">'Unnamed: 0'</span>])</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Credit_Mix</th>
      <th>Payment_of_Min_Amount</th>
      <th>Credit_Score</th>
      <th>Age</th>
      <th>Annual_Income</th>
      <th>Monthly_Inhand_Salary</th>
      <th>Num_Bank_Accounts</th>
      <th>Num_Credit_Card</th>
      <th>Interest_Rate</th>
      <th>Num_of_Loan</th>
      <th>...</th>
      <th>Occupation_Musician</th>
      <th>Occupation_Scientist</th>
      <th>Occupation_Teacher</th>
      <th>Occupation_Writer</th>
      <th>Payment_Behaviour_High_spent_Large_value_payments</th>
      <th>Payment_Behaviour_High_spent_Medium_value_payments</th>
      <th>Payment_Behaviour_High_spent_Small_value_payments</th>
      <th>Payment_Behaviour_Low_spent_Large_value_payments</th>
      <th>Payment_Behaviour_Low_spent_Medium_value_payments</th>
      <th>Payment_Behaviour_Low_spent_Small_value_payments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>-0.529412</td>
      <td>-0.336516</td>
      <td>-0.383675</td>
      <td>-0.75</td>
      <td>-0.666667</td>
      <td>-0.928571</td>
      <td>0.0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>-0.529412</td>
      <td>-0.336516</td>
      <td>0.000000</td>
      <td>-0.75</td>
      <td>-0.666667</td>
      <td>-0.928571</td>
      <td>0.0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>-0.529412</td>
      <td>-0.336516</td>
      <td>-0.383675</td>
      <td>-0.75</td>
      <td>-0.666667</td>
      <td>-0.928571</td>
      <td>0.0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>-0.529412</td>
      <td>-0.336516</td>
      <td>0.000000</td>
      <td>-0.75</td>
      <td>-0.666667</td>
      <td>-0.928571</td>
      <td>0.0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>-0.529412</td>
      <td>-0.336516</td>
      <td>-0.383675</td>
      <td>-0.75</td>
      <td>-0.666667</td>
      <td>-0.928571</td>
      <td>0.0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 40 columns</p>
</div>
</div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df_samp <span class="op">=</span> df.sample(frac <span class="op">=</span><span class="fl">.25</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>df_samp.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>(24450, 40)</code></pre>
</div>
</div>
</section>
<section id="data-selection" class="level1">
<h1>Data Selection</h1>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_samp.drop(columns<span class="op">=</span>[<span class="st">'Credit_Score'</span>])</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_samp[<span class="st">'Credit_Score'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="baseline-model-of-kmeans" class="level1">
<h1>Baseline Model of KMeans</h1>
<p>Here I set the initial n_clusters = 3 because the dataset has 3 labels.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>kmeans.fit(X)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>y_kmeans <span class="op">=</span> kmeans.predict(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>kmeans.cluster_centers_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>array([[ 1.25695203,  0.64928393, -0.22931014,  0.05113821,  0.01693268,
        -0.43686982, -0.12658147, -0.55429966, -0.42844069, -0.22067019,
        -0.887732  ,  0.05847756, -0.70162482, -0.43367844,  0.16249597,
        -0.27321347,  0.20518654,  0.35838052,  0.06268062,  0.05831353,
         0.0646715 ,  0.06293751,  0.06531372,  0.06268062,  0.05664376,
         0.06120352,  0.06081819,  0.06447884,  0.06255218,  0.06011175,
         0.06492839,  0.06062552,  0.13204033,  0.14058185,  0.2454563 ,
         0.11187464,  0.10525978,  0.13672853,  0.2600989 ],
       [ 1.23938852,  0.64449504, -0.09563487, -0.06118887, -0.11754005,
         0.38652626,  0.41443053,  0.55356272,  0.46588876,  0.75979834,
         0.39173036,  0.34881287,  0.53722557,  0.79457825, -0.05881617,
         0.38773015,  0.04825888, -0.18196787,  0.06391283,  0.07285738,
         0.06879167,  0.05691982,  0.06261181,  0.05822085,  0.06309969,
         0.06797853,  0.05545617,  0.06277443,  0.0637502 ,  0.0556188 ,
         0.05740771,  0.06033501,  0.13026508,  0.14295007,  0.25776549,
         0.11091234,  0.10473248,  0.1379086 ,  0.24573101],
       [ 1.25750916,  0.64981685,  0.16804568,  1.46091735,  1.43817175,
        -0.35393773, -0.38998779, -0.38178964, -0.24130037, -0.35653236,
        -0.44450549, -0.12441434, -0.49611722, -0.3107515 ,  0.16085472,
         1.16512457,  1.53221765,  1.69605523,  0.05641026,  0.05860806,
         0.05604396,  0.06117216,  0.07362637,  0.05750916,  0.06336996,
         0.07252747,  0.06117216,  0.06117216,  0.06117216,  0.05531136,
         0.06410256,  0.06923077,  0.12857143,  0.13333333,  0.25384615,
         0.11391941,  0.1003663 ,  0.13919414,  0.25934066]])</code></pre>
</div>
</div>
<p><strong>Inertia</strong> is not a normalized metric. The lower values of inertia are better and zero is optimal. But in very high-dimensional spaces, euclidean distances tend to become inflated (this is an instance of curse of dimensionality).</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>kmeans.inertia_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>158602.24501886335</code></pre>
</div>
</div>
<p>check how many of the samples were correctly labeled</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> kmeans.labels_</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>correct_labels <span class="op">=</span> <span class="bu">sum</span>(y <span class="op">==</span> labels)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Result: </span><span class="sc">%d</span><span class="st"> out of </span><span class="sc">%d</span><span class="st"> samples were correctly labeled."</span> <span class="op">%</span> (correct_labels, y.size))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Result: 8233 out of 24450 samples were correctly labeled.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Accuracy score: </span><span class="sc">{0:0.2f}</span><span class="st">'</span>. <span class="bu">format</span>(correct_labels<span class="op">/</span><span class="bu">float</span>(y.size)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy score: 0.34</code></pre>
</div>
</div>
<p>Here we can see that from the initial parameter, we get a pretty low clustering accuracy. This is not what we want so next I will use elbow method to find optimal number of clusters. This process could also be known as <strong>hyper-parameter tuning</strong>.</p>
<section id="hyper-parameter-tuning" class="level2">
<h2 class="anchored" data-anchor-id="hyper-parameter-tuning">Hyper-parameter Tuning</h2>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>cs <span class="op">=</span> []</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>):</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters <span class="op">=</span> i, init <span class="op">=</span> <span class="st">'k-means++'</span>, max_iter <span class="op">=</span> <span class="dv">300</span>, n_init <span class="op">=</span> <span class="dv">10</span>, random_state <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    kmeans.fit(X)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    cs.append(kmeans.inertia_)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>), cs)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'The Elbow Method'</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of clusters'</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'CS'</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Clustering_quarto_files/figure-html/cell-11-output-1.png" width="622" height="455"></p>
</div>
</div>
<p>By the above plot, we can see that there is a kink at k=3. Hence k=3 can be considered a good number of the cluster to cluster this data. But, we have seen that I have achieved a weak classification accuracy of 25% with k=3. So, my weak unsupervised classification model achieved a very weak classification accuracy of 25%. Next I will check the model accuracy with different number of clusters.</p>
<p><strong>K-Means model with 2 clusters</strong></p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>kmeans.fit(X)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># check how many of the samples were correctly labeled</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> kmeans.labels_</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>correct_labels <span class="op">=</span> <span class="bu">sum</span>(y <span class="op">==</span> labels)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Result: </span><span class="sc">%d</span><span class="st"> out of </span><span class="sc">%d</span><span class="st"> samples were correctly labeled."</span> <span class="op">%</span> (correct_labels, y.size))</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Accuracy score: </span><span class="sc">{0:0.2f}</span><span class="st">'</span>. <span class="bu">format</span>(correct_labels<span class="op">/</span><span class="bu">float</span>(y.size)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Result: 11470 out of 24450 samples were correctly labeled.
Accuracy score: 0.47</code></pre>
</div>
</div>
<p><strong>K-Means model with 4 clusters</strong></p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">4</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>kmeans.fit(X)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># check how many of the samples were correctly labeled</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> kmeans.labels_</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>correct_labels <span class="op">=</span> <span class="bu">sum</span>(y <span class="op">==</span> labels)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Result: </span><span class="sc">%d</span><span class="st"> out of </span><span class="sc">%d</span><span class="st"> samples were correctly labeled."</span> <span class="op">%</span> (correct_labels, y.size))</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Accuracy score: </span><span class="sc">{0:0.2f}</span><span class="st">'</span>. <span class="bu">format</span>(correct_labels<span class="op">/</span><span class="bu">float</span>(y.size)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Result: 5431 out of 24450 samples were correctly labeled.
Accuracy score: 0.22</code></pre>
</div>
</div>
<p><strong>Visualize the optimal model</strong></p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>bestK <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> bestK.fit_predict(X)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>adv <span class="op">=</span> X.copy()</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>adv[<span class="st">'nlabels'</span>] <span class="op">=</span> labels</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x<span class="op">=</span><span class="st">'Amount_invested_monthly'</span>, y<span class="op">=</span><span class="st">"Credit_Utilization_Ratio"</span>,hue<span class="op">=</span><span class="st">'nlabels'</span>,data<span class="op">=</span>adv)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Kmeans"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>Text(0.5, 1.0, 'Kmeans')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Clustering_quarto_files/figure-html/cell-14-output-2.png" width="601" height="455"></p>
</div>
</div>
<p>We have achieved a relatively high accuracy of 47% with k=2.</p>
</section>
<section id="results-and-conclusions" class="level2">
<h2 class="anchored" data-anchor-id="results-and-conclusions">Results and Conclusions</h2>
<p>In this part, I have implemented the most popular unsupervised clustering technique called K-Means Clustering.</p>
<p>I have applied the elbow method and find that k=3 (k is number of clusters) can be considered a good number of cluster to cluster this data.</p>
<p>I have find that the model has very high inertia of 638137. So, this is not a good model fit to the data.</p>
<p>I have achieved a weak classification accuracy of 25% with k=3 by our unsupervised model.</p>
<p>So, I have changed the value of k and find relatively higher classification accuracy of 47% with k=2.</p>
<p>Hence, we can conclude that k=2 being the optimal number of clusters.</p>
</section>
</section>
<section id="baseline-model-for-dbscan" class="level1">
<h1>Baseline Model for DBSCAN</h1>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.cluster <span class="im">import</span> homogeneity_score, completeness_score, v_measure_score, adjusted_rand_score, adjusted_mutual_info_score, silhouette_score</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="fl">0.3</span>, min_samples<span class="op">=</span><span class="dv">10</span>).fit(X)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>core_samples_mask <span class="op">=</span> np.zeros_like(db.labels_, dtype<span class="op">=</span><span class="bu">bool</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>core_samples_mask[db.core_sample_indices_] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> db.labels_</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of clusters in labels, ignoring noise if present.</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>n_clusters_ <span class="op">=</span> <span class="bu">len</span>(<span class="bu">set</span>(labels)) <span class="op">-</span> (<span class="dv">1</span> <span class="cf">if</span> <span class="op">-</span><span class="dv">1</span> <span class="kw">in</span> labels <span class="cf">else</span> <span class="dv">0</span>)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>n_noise_ <span class="op">=</span> <span class="bu">list</span>(labels).count(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated number of clusters: </span><span class="sc">%d</span><span class="st">"</span> <span class="op">%</span> n_clusters_)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated number of noise points: </span><span class="sc">%d</span><span class="st">"</span> <span class="op">%</span> n_noise_)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Homogeneity: </span><span class="sc">%0.3f</span><span class="st">"</span> <span class="op">%</span> homogeneity_score(y, labels))</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Completeness: </span><span class="sc">%0.3f</span><span class="st">"</span> <span class="op">%</span> completeness_score(y, labels))</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"V-measure: </span><span class="sc">%0.3f</span><span class="st">"</span> <span class="op">%</span> v_measure_score(y, labels))</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Adjusted Rand Index: </span><span class="sc">%0.3f</span><span class="st">"</span> <span class="op">%</span> adjusted_rand_score(y, labels))</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Adjusted Mutual Information: </span><span class="sc">%0.3f</span><span class="st">"</span></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    <span class="op">%</span> adjusted_mutual_info_score(y, labels)</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Silhouette Coefficient: </span><span class="sc">%0.3f</span><span class="st">"</span> <span class="op">%</span> silhouette_score(X, labels))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated number of clusters: 375
Estimated number of noise points: 14485
Homogeneity: 0.083
Completeness: 0.027
V-measure: 0.041
Adjusted Rand Index: 0.005
Adjusted Mutual Information: 0.033</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Silhouette Coefficient: 0.234</code></pre>
</div>
</div>
<p><strong>Using Euclidean distance method to find optimum epsilon distance(eps)</strong></p>
<p>Biggest challenge with DBSCAN algorithm is to find right hyper parameters(eps and min_samples values) to model the algorithm.</p>
<p>In this method, we are trying to sort the data and try to find the distance among its neighbors to find the minimum distance between them and plot the minimum distance. This will essentially give us the elbow curve to find density of the data points and their minimum distance(eps) values</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.cluster <span class="im">import</span> silhouette_score</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>range_eps <span class="op">=</span> [<span class="fl">0.1</span>,<span class="fl">0.2</span>,<span class="fl">0.3</span>,<span class="fl">0.4</span>,<span class="fl">0.5</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">5</span>]</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> range_eps:</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"eps value is "</span><span class="op">+</span> <span class="bu">str</span>(i))</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    db <span class="op">=</span> DBSCAN(eps<span class="op">=</span>i,min_samples<span class="op">=</span><span class="dv">5</span>).fit(X)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    core_samples_mask <span class="op">=</span> np.zeros_like(db.labels_, dtype<span class="op">=</span><span class="bu">bool</span>)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    core_samples_mask[db.core_sample_indices_] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> db.labels_</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(set(labels))</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>    silhouette_avg <span class="op">=</span> silhouette_score(X, labels)</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"For eps value = "</span><span class="op">+</span><span class="bu">str</span>(i), labels, <span class="st">"The average silhouette score is :"</span>, silhouette_avg)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>eps value is 0.1</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For eps value = 0.1 [ 0 -1 -1 ... -1 -1 -1] The average silhouette score is : 0.26062834497862825
eps value is 0.2</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For eps value = 0.2 [ 0 -1 -1 ... -1 -1 -1] The average silhouette score is : 0.26062834497862825
eps value is 0.3</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For eps value = 0.3 [ 0 -1 -1 ... -1 -1 -1] The average silhouette score is : 0.26062834497862825
eps value is 0.4</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For eps value = 0.4 [ 0 -1 -1 ... -1 -1 -1] The average silhouette score is : 0.26062834497862825
eps value is 0.5</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For eps value = 0.5 [ 0 -1 -1 ... -1 -1 -1] The average silhouette score is : 0.26062834497862825
eps value is 1</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For eps value = 1 [ 0 -1 -1 ... -1 55 -1] The average silhouette score is : 0.04498314839261654
eps value is 2</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For eps value = 2 [0 0 0 ... 0 0 0] The average silhouette score is : -0.04994972934496422
eps value is 4</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For eps value = 4 [0 0 0 ... 0 0 0] The average silhouette score is : 0.6246776260900448
eps value is 5</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For eps value = 5 [0 0 0 ... 0 0 0] The average silhouette score is : 0.636241813840908</code></pre>
</div>
</div>
<p>Here we can see obviously that eps value 1 gives us the best silhouette score. So we choose this eps parameter as 1.</p>
<p><strong>Find the ‘min_samples’ hyper parameter through right cluster formation method</strong></p>
<p>We choose the <code>eps=1</code> to be optimal parameter. As we have already found the ‘eps value’ to be 1. Now feeding that value to DBSCAN algorithm through various ranges of min samples from a wide range, we can find the right ‘min_samples’ value which yields us right no. of clusters. From below its evident ‘min_samples’ value should be 145 as it yields no. of clusters to be 3 which is proven by K means with silhouette score algorithm above.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_samples, silhouette_score</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>min_samples <span class="op">=</span> [<span class="dv">80</span>,<span class="dv">90</span>,<span class="dv">100</span>,<span class="dv">120</span>,<span class="dv">130</span>,<span class="dv">140</span>,<span class="dv">145</span>,<span class="dv">150</span>]</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> min_samples:</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"min_sample value is: "</span> <span class="op">+</span> <span class="bu">str</span>(i))</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    db <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="dv">1</span>, min_samples<span class="op">=</span>i).fit(X)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    core_samples_mask <span class="op">=</span> np.zeros_like(db.labels_,dtype<span class="op">=</span><span class="bu">bool</span>)</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    core_samples_mask[db.core_sample_indices_]<span class="op">=</span><span class="va">True</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> <span class="bu">set</span>([label <span class="cf">for</span> label <span class="kw">in</span> db.labels_ <span class="cf">if</span> label<span class="op">&gt;=</span><span class="dv">0</span>])</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"For min_samples values = "</span><span class="op">+</span><span class="bu">str</span>(i), <span class="st">"Total number of clusters are "</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">len</span>(<span class="bu">set</span>(labels))))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>min_sample value is: 80</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For min_samples values = 80 Total number of clusters are 40
min_sample value is: 90</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For min_samples values = 90 Total number of clusters are 34
min_sample value is: 100</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For min_samples values = 100 Total number of clusters are 34
min_sample value is: 120</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For min_samples values = 120 Total number of clusters are 26
min_sample value is: 130</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For min_samples values = 130 Total number of clusters are 16
min_sample value is: 140</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For min_samples values = 140 Total number of clusters are 10
min_sample value is: 145</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For min_samples values = 145 Total number of clusters are 7
min_sample value is: 150</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>For min_samples values = 150 Total number of clusters are 4</code></pre>
</div>
</div>
<p><strong>Build the DBSCAN algorithm using above ‘eps’ value and ‘min_samples’</strong></p>
<p>Using eps as 1 and min_samples as 145 to train the optimal DBSCAN model.</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> DBSCAN(eps <span class="op">=</span> <span class="dv">1</span>, min_samples<span class="op">=</span><span class="dv">145</span>).fit(X)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>core_samples_mask <span class="op">=</span> np.zeros_like(db.labels_, dtype<span class="op">=</span><span class="bu">bool</span>)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>core_samples_mask[db.core_sample_indices_] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> db.labels_</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>n_clusters_ <span class="op">=</span> <span class="bu">len</span>(<span class="bu">set</span>(labels))</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>n_noise_ <span class="op">=</span> <span class="bu">list</span>(labels).count(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated number of clusters: </span><span class="sc">%d</span><span class="st">"</span> <span class="op">%</span> n_clusters_)</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated number of noise points: </span><span class="sc">%d</span><span class="st">"</span> <span class="op">%</span> n_noise_)</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> db.labels_</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>correct_labels <span class="op">=</span> <span class="bu">sum</span>(y <span class="op">==</span> labels)</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Result: </span><span class="sc">%d</span><span class="st"> out of </span><span class="sc">%d</span><span class="st"> samples were correctly labeled."</span> <span class="op">%</span> (correct_labels, y.size))</span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Accuracy score: </span><span class="sc">{0:0.2f}</span><span class="st">'</span>. <span class="bu">format</span>(correct_labels<span class="op">/</span><span class="bu">float</span>(y.size)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated number of clusters: 8
Estimated number of noise points: 23051
Result: 313 out of 24450 samples were correctly labeled.
Accuracy score: 0.01</code></pre>
</div>
</div>
<p><strong>Visualize the optimal model</strong></p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="dv">1</span>, min_samples<span class="op">=</span><span class="dv">145</span>).fit(X)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>adv[<span class="st">'Labels'</span>] <span class="op">=</span> db.labels_</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(adv[<span class="st">'Amount_invested_monthly'</span>], adv[<span class="st">'Credit_Utilization_Ratio'</span>], hue<span class="op">=</span>adv[<span class="st">'Labels'</span>], </span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>                palette<span class="op">=</span>sns.color_palette(<span class="st">'hls'</span>, np.unique(db.labels_).shape[<span class="dv">0</span>]))</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Optimal DBSCAN'</span>)</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/wangshiyu/opt/anaconda3/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning:

Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Clustering_quarto_files/figure-html/cell-19-output-2.png" width="973" height="677"></p>
</div>
</div>
<section id="results-and-conclusions-1" class="level2">
<h2 class="anchored" data-anchor-id="results-and-conclusions-1">Results and Conclusions</h2>
<p>From a two-step hyper-parameter tuning, I determine the optimal <code>eps</code> and <code>min_samples</code>. Choosing the optimal eps based on the best silhouette score and the optimal min_samples based on the most reasonable number of clusters. Seeing the accuracy, we could know that compared with the true label from the initial data set, it is a pretty weak method to do the clustering. But the accuracy is just a reference because the DBSCAN is a unsupervised clustering method which does not contain labels. So generally speaking I think the result here for my data set is acceptable.</p>
</section>
</section>
<section id="baseline-model-for-hierachial-clustering" class="level1">
<h1>Baseline Model for Hierachial Clustering</h1>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> <span class="bu">list</span>(<span class="bu">zip</span>(X, y))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.cluster.hierarchy <span class="im">as</span> shc</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">7</span>))  </span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Dendrograms"</span>)  </span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>dend <span class="op">=</span> shc.dendrogram(shc.linkage(X, method<span class="op">=</span><span class="st">'ward'</span>))</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Samples"</span>)</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Distance"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>Text(0, 0.5, 'Distance')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Clustering_quarto_files/figure-html/cell-21-output-2.png" width="823" height="607"></p>
</div>
</div>
<p>The x-axis contains the samples and y-axis represents the distance between these samples. The vertical line with maximum distance is the blue line and hence we can decide a threshold of 150 and cut the dendrogram:</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">7</span>))  </span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Dendrograms"</span>)  </span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>dend <span class="op">=</span> shc.dendrogram(shc.linkage(X, method<span class="op">=</span><span class="st">'ward'</span>))</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span><span class="dv">150</span>, color<span class="op">=</span><span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Samples"</span>)</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Distance"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>Text(0, 0.5, 'Distance')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Clustering_quarto_files/figure-html/cell-22-output-2.png" width="823" height="607"></p>
</div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> AgglomerativeClustering</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>cluster <span class="op">=</span> AgglomerativeClustering(n_clusters<span class="op">=</span><span class="dv">3</span>, affinity<span class="op">=</span><span class="st">'euclidean'</span>, linkage<span class="op">=</span><span class="st">'ward'</span>)  </span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>cluster.fit_predict(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>array([2, 1, 2, ..., 2, 2, 2])</code></pre>
</div>
</div>
<p>We can see the values of 0s, 1s and 2s in the output since we defined 3 clusters. 0 represents the points that belong to the first cluster and 1 represents points in the second cluster and 2 represents points in the third cluster. Next let’s see the accuracy of this clustering.</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> cluster.labels_</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>correct_labels <span class="op">=</span> <span class="bu">sum</span>(y <span class="op">==</span> labels)</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Result: </span><span class="sc">%d</span><span class="st"> out of </span><span class="sc">%d</span><span class="st"> samples were correctly labeled."</span> <span class="op">%</span> (correct_labels, y.size))</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Accuracy score: </span><span class="sc">{0:0.2f}</span><span class="st">'</span>. <span class="bu">format</span>(correct_labels<span class="op">/</span><span class="bu">float</span>(y.size)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Result: 6773 out of 24450 samples were correctly labeled.
Accuracy score: 0.28</code></pre>
</div>
</div>
<p>Here we can see from the accuracy score which is only 28% that it is a very weak clustering. So next I will try some other hyper-parameters to see whether it can promote the model accuracy.</p>
<section id="hyper-parameter-tuning-1" class="level2">
<h2 class="anchored" data-anchor-id="hyper-parameter-tuning-1">Hyper-parameter Tuning</h2>
<p>In this part, I implement the hierachial clustering using other parameters. The hyper-parameter is <code>linkage</code>:</p>
<p>linkage: used to specify the linkage algorithm</p>
<ul>
<li>‘ward’: single-linkage single-linkage, using dmin</li>
<li>‘complete’: full linkage-complete-linkage, using dmax</li>
<li>‘average’: average linkage-linkage algorithm, using davg</li>
</ul>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># linkage='complete'</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>cluster <span class="op">=</span> AgglomerativeClustering(n_clusters<span class="op">=</span><span class="dv">3</span>, affinity<span class="op">=</span><span class="st">'euclidean'</span>, linkage<span class="op">=</span><span class="st">'complete'</span>)  </span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>cluster.fit_predict(X)</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> cluster.labels_</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>correct_labels <span class="op">=</span> <span class="bu">sum</span>(y <span class="op">==</span> labels)</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Result: </span><span class="sc">%d</span><span class="st"> out of </span><span class="sc">%d</span><span class="st"> samples were correctly labeled."</span> <span class="op">%</span> (correct_labels, y.size))</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Accuracy score: </span><span class="sc">{0:0.2f}</span><span class="st">'</span>. <span class="bu">format</span>(correct_labels<span class="op">/</span><span class="bu">float</span>(y.size)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Result: 7032 out of 24450 samples were correctly labeled.
Accuracy score: 0.29</code></pre>
</div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># linkage='average'</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>cluster <span class="op">=</span> AgglomerativeClustering(n_clusters<span class="op">=</span><span class="dv">3</span>, affinity<span class="op">=</span><span class="st">'euclidean'</span>, linkage<span class="op">=</span><span class="st">'average'</span>)  </span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>cluster.fit_predict(X)</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> cluster.labels_</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>correct_labels <span class="op">=</span> <span class="bu">sum</span>(y <span class="op">==</span> labels)</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Result: </span><span class="sc">%d</span><span class="st"> out of </span><span class="sc">%d</span><span class="st"> samples were correctly labeled."</span> <span class="op">%</span> (correct_labels, y.size))</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Accuracy score: </span><span class="sc">{0:0.2f}</span><span class="st">'</span>. <span class="bu">format</span>(correct_labels<span class="op">/</span><span class="bu">float</span>(y.size)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Result: 7068 out of 24450 samples were correctly labeled.
Accuracy score: 0.29</code></pre>
</div>
</div>
<p>The results show that hierachial clustering is a relative weak method for my data set. I have achieved a relatively high accuracy of 29% with ‘complete’ and ‘average’ linkage.</p>
</section>
<section id="results-and-conclusions-2" class="level2">
<h2 class="anchored" data-anchor-id="results-and-conclusions-2">Results and Conclusions</h2>
<p>In this part, I have implemented the hierachial Clustering.</p>
<p>I have applied three different hyper parameters for linkage function and find that average and complete can be considered good ways to link.</p>
<p>Since the overall accuracy is pretty low, I don’t think this is not a good model fit to the data.</p>
<p>I have achieved a weak classification accuracy of 29%.</p>
</section>
</section>
<section id="final-results" class="level1">
<h1>Final Results</h1>
<p>In this work, we have applied the three most common clustering algorithms on the same dataset and obtained the corresponding results. In kmeans, we first classified the data into three categories based on intuition, but the clustering results were poorly matched to the labels that came with the original data, with a maximum of 47% after model tuning, but this value is only a reference, because kmeans and the two algorithms mentioned below are unsupervised learning methods.</p>
<p>In the second part, I implemented the DBSCAN algorithm on the dataset, using scikit learn. in this part, I parametrized two parameters, eps and min_samples, choosing the optimal eps based on the best silhouette score and the optimal min_samples based on the most reasonable number of clusters.</p>
<p>In the last part I did hierarchical clustering. And dendrograms are used to visualize the results. The reasonable clustering result is decided based on the divergence of dendrograms. In this part I make parameter selection for linkage, choosing among the optional methods of complete, ward and average.</p>
</section>
<section id="conclusions" class="level1">
<h1>Conclusions</h1>
<p>Overall, I think kmeans is the most ideal algorithm for clustering among these three methods, because its clustering result has the highest similarity to the original label of the data, and the complexity of the model is also the lowest, saving the training time and efficiency.</p>
</section>
<section id="references" class="level1">
<h1>References</h1>
<ol type="1">
<li>https://medium.com/<span class="citation" data-cites="mohantysandip/a-step-by-step-approach-to-solve-dbscan-algorithms-by-tuning-its-hyper-parameters-93e693a91289">@mohantysandip/a-step-by-step-approach-to-solve-dbscan-algorithms-by-tuning-its-hyper-parameters-93e693a91289</span></li>
<li>https://www.w3schools.com/python/python_ml_hierarchial_clustering.asp</li>
</ol>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>