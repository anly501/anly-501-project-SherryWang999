---
title: "Data Gathering by R"
author: "Shiyu Wang"
date: "9/12/2022"
output: html_document
---
This data gathering process was finished by python and used Twitter API to grab some text data from recent tweets. Then I painted a wordcloud to show which words in the topic appear most. It is easy but will be useful to my future work to finish the project.

I'm gonna use the NLP methods to do some sentiment analysis and the result will be discussed in my project portfolio.
```{r}
library("selectr")
library("rvest")
library("xml2")
library(rtweet) # for scraping tweets
library(wordcloud2) # for generating really cool looking wordclouds
library(tm) # for text minning
library(dplyr) # loads of fun stuff including piping
library(twitteR)
library(ROAuth)
library(jsonlite)
```

```{r}
consumerKey = 'Apx8TT3mHth1uKedUxcHPiR2Q'
consumerSecret = 'A6vKdRrqHvz9EDL5WJQJMzXwlH7fCUMV8MbQn2ULkwM5XXrVqk'
access_Token = '1298010161949421568-UJZh6bAJOv6EJl13VP1cp2wolnPguG'
access_Secret = 'lwsZju1YqcNbv8B6ETgVGbq6MWn8zNZGpfUfPM6aAwxVr'
```

```{r}
### Properly parse our API keys 

consumerKey=as.character(consumerKey)
consumerSecret=as.character(consumerSecret)
access_Token=as.character(access_Token)
access_Secret=as.character(access_Secret)

requestURL='https://api.twitter.com/oauth/request_token'
accessURL='https://api.twitter.com/oauth/access_token'
authURL='https://api.twitter.com/oauth/authorize'
```

```{r}
setup_twitter_oauth(consumerKey,consumerSecret,access_Token,access_Secret)
```
```{r}
Search1<-twitteR::searchTwitter("Personal Credit",n=500, since="2022-04-01")
#Search2<-twitteR::searchTwitter("#photography",n=50, since="2022-01-01")
TweetsDF<- twListToDF(Search1)
#(TweetsDF$text[1])

########## Place Tweets in a new file ###################
FName = "MyFileExample.txt"
## Start the file
MyFile <- file(FName)
## Write Tweets to file
cat(unlist(TweetsDF), " ", file=MyFile, sep="\n")
close(MyFile)
```

```{r}
TweetsDF = twListToDF(Search1)

TweetsDF$text <- gsub("[^[:alnum:][:blank:]?&/\\-]", "",TweetsDF$text) # remove alphanumeric characters 
TweetsDF$text <- gsub("https\\S*", "",TweetsDF$text) # remove hyperlinks
#TweetsDF$text = gsub("(?!(#|@))[[:punct:]]", "", text, perl = T) 
# remove all punctuations except # and @. 
```

```{r}
#create a corpus to allow us clean the text column with tm
tweets.corpus <- Corpus(VectorSource(TweetsDF$text))


tweets.corpus <- tweets.corpus %>%
  tm_map(removeNumbers) %>% # removes numbers from text
  tm_map(removePunctuation) %>% # removes punctuation from text
  tm_map(stripWhitespace) %>% # trims the text of whitespace
  tm_map(content_transformer(tolower)) %>% # convert text to lowercase
  tm_map(removeWords,stopwords("english")) %>% # remove stopwords
  tm_map(removeWords,stopwords("SMART")) # remove stopwords not removed from previous line
```
```{r}
tdm <- TermDocumentMatrix(tweets.corpus) %>% # create a term document matrix
      as.matrix()

words <- sort(rowSums(tdm), decreasing = TRUE) # count all occurrences of each word and group them
df <- data.frame(word = names(words), freq = words) # convert it to a dataframe
head(df) # visualize!
```

```{r}
set.seed(1234) # for reproducibility
wcloud <- wordcloud2(df,   # generate word cloud
                     size = 1.5,
                     color= 'random-dark', # set colors
                     #shape = 'pentagon',
                     rotateRatio = 0) #horizontal looks better, but what do you think?
wcloud
```

